{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Chapter2_Create_Own_Anime_Character.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_GAN_demo_anime_aharacter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo2iHzciL5T7",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Inputs for the Network\n",
        "\n",
        "We will need to download the data from a drive location so we import the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFwNKvQmysyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5tYOwQAwBg7",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "- original: https://towardsdatascience.com/an-end-to-end-introduction-to-gans-bf253f1fa52f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdnR4u07Lzj0",
        "colab_type": "code",
        "outputId": "d5baeeba-226d-4e1f-edf7-e35a6ac5967e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "\n",
        "from pydrive.drive import GoogleDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 30.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 35.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 37.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 39.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 43.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 44.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 44.4MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 46.2MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 47.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 47.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 47.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 47.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 47.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 47.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 47.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 47.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 47.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pGshn9fMUlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NReWIdZKMZ9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1i1M7GQZY5e8TYnFyD0ov-J7YjrI_YIGI'})\n",
        "download.GetContentFile('data.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYceyC7jOTh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip data.zip # > /dev/null # Dont show any output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SF04Zzjd4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bt1R5ylMI8P",
        "colab_type": "text"
      },
      "source": [
        "Also the keras imports we have to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4khmw9L4Jy",
        "colab_type": "code",
        "outputId": "5fabc014-f27d-47f6-e6f9-887c99bef976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import time\n",
        "import cv2\n",
        "import scipy\n",
        "from PIL import Image\n",
        "import matplotlib.gridspec as gridspec\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import keras.backend as K\n",
        "#from scipy.interpolate import spline\n",
        "K.set_image_dim_ordering('tf')\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.layers import Input, merge\n",
        "from keras.initializers import RandomNormal\n",
        "K.set_image_dim_ordering('tf')\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True \n",
        "set_session(tf.Session(config=config))\n",
        "from collections import deque"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJQsLJ_TQJ6o",
        "colab_type": "text"
      },
      "source": [
        "# Visualize some images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbnfNGwljzB6",
        "colab_type": "code",
        "outputId": "4446e6d1-dd70-4f17-85a8-1bf409303677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filenames = glob.glob('animeface-character-dataset/*/*/*.pn*')\n",
        "\n",
        "print(\"Num_Images: \",len(filenames))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num_Images:  14490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbsE-SPjPCoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(5):\n",
        "    img = plt.imread(filenames[i], 0)\n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(img.shape)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnCn6BuiP57A",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing the Images\n",
        "\n",
        "Some helper preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUWjP_XzPIKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to normalize image pixels.\n",
        "def norm_img(img):\n",
        "    '''A function to Normalize Images.\n",
        "    Input:\n",
        "        img : Original image as numpy array.\n",
        "    Output: Normailized Image as numpy array\n",
        "    '''\n",
        "    img = (img / 127.5) - 1\n",
        "    return img\n",
        "\n",
        "def denorm_img(img):\n",
        "    '''A function to Denormailze, i.e. recreate image from normalized image\n",
        "    Input:\n",
        "        img : Normalized image as numpy array.\n",
        "    Output: Original Image as numpy array\n",
        "    '''\n",
        "    img = (img + 1) * 127.5\n",
        "    return img.astype(np.uint8) \n",
        "\n",
        "def sample_from_dataset(batch_size, image_shape, data_dir=None):\n",
        "    '''Create a batch of image samples by sampling random images from a data directory.\n",
        "    Resizes the image using image_shape and normalize the images.\n",
        "    Input:\n",
        "        batch_size : Sample size required\n",
        "        image_size : Size that Image should be resized to\n",
        "        data_dir : Path of directory where training images are placed.\n",
        "\n",
        "    Output:\n",
        "        sample : batch of processed images \n",
        "    '''\n",
        "    sample_dim = (batch_size,) + image_shape\n",
        "    sample = np.empty(sample_dim, dtype=np.float32)\n",
        "    all_data_dirlist = list(glob.glob(data_dir))\n",
        "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size)\n",
        "    for index,img_filename in enumerate(sample_imgs_paths):\n",
        "        image = Image.open(img_filename)\n",
        "        image = image.resize(image_shape[:-1])\n",
        "        image = image.convert('RGB') \n",
        "        image = np.asarray(image)\n",
        "        image = norm_img(image)\n",
        "        sample[index,...] = image\n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN8GmD6eQUSu",
        "colab_type": "text"
      },
      "source": [
        "# Keras Implementation of DCGAN\n",
        "\n",
        "## 1. Generate Noise Vector for Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlYRdfZ6PQ5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_noise(batch_size, noise_shape):\n",
        "    ''' Generates a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)\n",
        "    Input:\n",
        "        batch_size : size of batch\n",
        "        noise_shape: shape of noise vector, normally kept as 100 \n",
        "    Output:a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)     \n",
        "    '''\n",
        "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcclyHEZQnUR",
        "colab_type": "text"
      },
      "source": [
        "## 2. Generator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMrJM7u0QdZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gen_normal(noise_shape):\n",
        "    ''' This function takes as input shape of the noise vector and creates the Keras generator    architecture.\n",
        "    '''\n",
        "    kernel_init = 'glorot_uniform'    \n",
        "    gen_input = Input(shape = noise_shape) \n",
        "    \n",
        "    # Transpose 2D conv layer 1. \n",
        "    generator = Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = (1,1), padding = \"valid\", data_format = \"channels_last\", kernel_initializer = kernel_init)(gen_input)\n",
        "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "    generator = LeakyReLU(0.2)(generator)\n",
        "    \n",
        "    # Transpose 2D conv layer 2.\n",
        "    generator = Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "    generator = LeakyReLU(0.2)(generator)\n",
        "    \n",
        "    # Transpose 2D conv layer 3.\n",
        "    generator = Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "    generator = LeakyReLU(0.2)(generator)\n",
        "    \n",
        "    # Transpose 2D conv layer 4.\n",
        "    generator = Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "    generator = LeakyReLU(0.2)(generator)\n",
        "    \n",
        "    # conv 2D layer 1.\n",
        "    generator = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
        "    generator = LeakyReLU(0.2)(generator)\n",
        "    \n",
        "    # Final Transpose 2D conv layer 5 to generate final image. Filter size 3 for 3 image channel\n",
        "    generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
        "    \n",
        "    # Tanh activation to get final normalized image\n",
        "    generator = Activation('tanh')(generator)\n",
        "    \n",
        "    # defining the optimizer and compiling the generator model.\n",
        "    gen_opt = Adam(lr=0.00015, beta_1=0.5)\n",
        "    generator_model = Model(input = gen_input, output = generator)\n",
        "    generator_model.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
        "    generator_model.summary()\n",
        "    return generator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdDIoerFQx8F",
        "colab_type": "text"
      },
      "source": [
        "## 3. Discriminator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzjJC19JQqdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_disc_normal(image_shape=(64,64,3)):\n",
        "    dropout_prob = 0.4\n",
        "    kernel_init = 'glorot_uniform'\n",
        "    dis_input = Input(shape = image_shape)\n",
        "    \n",
        "    # Conv layer 1:\n",
        "    discriminator = Conv2D(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(dis_input)\n",
        "    discriminator = LeakyReLU(0.2)(discriminator)\n",
        "    # Conv layer 2:\n",
        "    discriminator = Conv2D(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "    discriminator = LeakyReLU(0.2)(discriminator)\n",
        "    # Conv layer 3:   \n",
        "    discriminator = Conv2D(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "    discriminator = LeakyReLU(0.2)(discriminator)\n",
        "    # Conv layer 4:\n",
        "    discriminator = Conv2D(filters = 512, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
        "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
        "    discriminator = LeakyReLU(0.2)(discriminator)#discriminator = MaxPooling2D(pool_size=(2, 2))(discriminator)\n",
        "    # Flatten\n",
        "    discriminator = Flatten()(discriminator)\n",
        "    # Dense Layer\n",
        "    discriminator = Dense(1)(discriminator)\n",
        "    # Sigmoid Activation\n",
        "    discriminator = Activation('sigmoid')(discriminator)\n",
        "    # Optimizer and Compiling model\n",
        "    dis_opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    discriminator_model = Model(input = dis_input, output = discriminator)\n",
        "    discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
        "    discriminator_model.summary()\n",
        "    return discriminator_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnCOqAItQ58Q",
        "colab_type": "text"
      },
      "source": [
        "# Training and Saving Model\n",
        "\n",
        "## 1. Specify Training parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AIl-8kWThY8",
        "colab_type": "text"
      },
      "source": [
        "Running for 2000 steps only to save time. You can run for more if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9FHW3S6RVUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTlbtR4jRY0j",
        "colab_type": "code",
        "outputId": "93a2caaf-6fc1-4eff-e325-298a9df2c9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  animeface-character-dataset  data.zip  images  __MACOSX  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VUXoghvQ1mV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape of noise vector to be input to the Generator\n",
        "noise_shape = (1,1,100)\n",
        "# Number of steps for training. num_epochs = num_steps*batch_size/data_size\n",
        "num_steps = 2000\n",
        "# batch size for training.\n",
        "batch_size = 64\n",
        "# Location to save images and logs \n",
        "img_save_dir = \"images/\"\n",
        "# Image size to reshape to\n",
        "image_shape = (64,64,3)\n",
        "# Location of data directory\n",
        "data_dir = \"animeface-character-dataset/*/*/*.pn*\"\n",
        "# set up log and save directories\n",
        "log_dir = img_save_dir\n",
        "save_model_dir = img_save_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3lU4M53RlkX",
        "colab_type": "text"
      },
      "source": [
        "## 2. Helper Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQQVL-v3REci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_img_batch(img_batch,img_save_dir):\n",
        "    '''Takes as input a image batch and a img_save_dir and saves 16 images from the batch in a 4x4 grid in the img_save_dir\n",
        "    '''\n",
        "    plt.figure(figsize=(16,16))\n",
        "    gs1 = gridspec.GridSpec(4, 4)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "    rand_indices = np.random.choice(img_batch.shape[0],16,replace=False)\n",
        "    for i in range(16):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        rand_index = rand_indices[i]\n",
        "        image = img_batch[rand_index, :,:,:]\n",
        "        fig = plt.imshow(denorm_img(image))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(img_save_dir,bbox_inches='tight',pad_inches=0)\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6jy3K14RquA",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create Discriminator and Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kUdcuc8RGRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = get_disc_normal(image_shape)\n",
        "generator = get_gen_normal(noise_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIl36jPrVpXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(generator, to_file='gen_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OsRNSwlWQ6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(discriminator, to_file='dis_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-VjtIJLR1zY",
        "colab_type": "text"
      },
      "source": [
        "## 4. Combine Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPJucnHdRuxR",
        "colab_type": "code",
        "outputId": "46c5098d-ead7-4e62-c732-fea7449db939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "discriminator.trainable = False\n",
        "\n",
        "# Optimizer for the GAN\n",
        "opt = Adam(lr=0.00015, beta_1=0.5) #same as generator\n",
        "# Input to the generator\n",
        "gen_inp = Input(shape=noise_shape)\n",
        "\n",
        "GAN_inp = generator(gen_inp)\n",
        "GAN_opt = discriminator(GAN_inp)\n",
        "\n",
        "# Final GAN\n",
        "gan = Model(input = gen_inp, output = GAN_opt)\n",
        "gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
        "\n",
        "plot_model(gan, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"mo...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6ojzAekR_Bu",
        "colab_type": "text"
      },
      "source": [
        "## 5. Assemble all blocks and train and save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L97qfUgkR5Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use a fixed noise vector to see how the GAN Images transition through time on a fixed noise. \n",
        "fixed_noise = gen_noise(16,noise_shape)\n",
        "\n",
        "# To keep Track of losses\n",
        "avg_disc_fake_loss = []\n",
        "avg_disc_real_loss = []\n",
        "avg_GAN_loss = []\n",
        "\n",
        "# We will run for num_steps iterations\n",
        "for step in range(num_steps): \n",
        "    tot_step = step\n",
        "    print(\"Begin step: \", tot_step)\n",
        "    # to keep track of time per step\n",
        "    step_begin_time = time.time() \n",
        "    \n",
        "    # sample a batch of normalized images from the dataset\n",
        "    real_data_X = sample_from_dataset(batch_size, image_shape, data_dir=data_dir)\n",
        "    \n",
        "    # Genearate noise to send as input to the generator\n",
        "    noise = gen_noise(batch_size,noise_shape)\n",
        "    \n",
        "    # Use generator to create(predict) images\n",
        "    fake_data_X = generator.predict(noise)\n",
        "    \n",
        "    # Save predicted images from the generator every 10th step\n",
        "    if (tot_step % 100) == 0:\n",
        "        step_num = str(tot_step).zfill(4)\n",
        "        save_img_batch(fake_data_X,img_save_dir+step_num+\"_image.png\")\n",
        "    \n",
        "    # Create the labels for real and fake data. We don't give exact ones and zeros but add a small amount of noise. This is an important GAN training trick\n",
        "    real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "    fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "        \n",
        "    # train the discriminator using data and labels\n",
        "\n",
        "    discriminator.trainable = True\n",
        "    generator.trainable = False\n",
        "\n",
        "    # Training Discriminator seperately on real data\n",
        "    dis_metrics_real = discriminator.train_on_batch(real_data_X,real_data_Y) \n",
        "    # training Discriminator seperately on fake data\n",
        "    dis_metrics_fake = discriminator.train_on_batch(fake_data_X,fake_data_Y) \n",
        "    \n",
        "    print(\"Disc: real loss: %f fake loss: %f\" % (dis_metrics_real[0], dis_metrics_fake[0]))\n",
        "    \n",
        "    # Save the losses to plot later\n",
        "    avg_disc_fake_loss.append(dis_metrics_fake[0])\n",
        "    avg_disc_real_loss.append(dis_metrics_real[0])\n",
        "    \n",
        "    # Train the generator using a random vector of noise and its labels (1's with noise)\n",
        "    generator.trainable = True\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    GAN_X = gen_noise(batch_size,noise_shape)\n",
        "    GAN_Y = real_data_Y\n",
        "   \n",
        "    gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)\n",
        "    print(\"GAN loss: %f\" % (gan_metrics[0]))\n",
        "    \n",
        "    # Log results by opening a file in append mode\n",
        "    text_file = open(log_dir+\"\\\\training_log.txt\", \"a\")\n",
        "    text_file.write(\"Step: %d Disc: real loss: %f fake loss: %f GAN loss: %f\\n\" % (tot_step, dis_metrics_real[0], dis_metrics_fake[0],gan_metrics[0]))\n",
        "    text_file.close()\n",
        "\n",
        "    # save GAN loss to plot later\n",
        "    avg_GAN_loss.append(gan_metrics[0])\n",
        "            \n",
        "    end_time = time.time()\n",
        "    diff_time = int(end_time - step_begin_time)\n",
        "    print(\"Step %d completed. Time took: %s secs.\" % (tot_step, diff_time))\n",
        "    \n",
        "    # save model at every 500 steps\n",
        "    if ((tot_step+1) % 500) == 0:\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        print(\"Average Disc_fake loss: %f\" % (np.mean(avg_disc_fake_loss))) \n",
        "        print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss))) \n",
        "        print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
        "        print(\"-----------------------------------------------------------------\")\n",
        "        discriminator.trainable = False\n",
        "        generator.trainable = False\n",
        "        # predict on fixed_noise\n",
        "        fixed_noise_generate = generator.predict(noise)\n",
        "        step_num = str(tot_step).zfill(4)\n",
        "        save_img_batch(fixed_noise_generate,img_save_dir+step_num+\"fixed_image.png\")\n",
        "        generator.save(save_model_dir+str(tot_step)+\"_GENERATOR_weights_and_arch.hdf5\")\n",
        "        discriminator.save(save_model_dir+str(tot_step)+\"_DISCRIMINATOR_weights_and_arch.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgtNsIXglDk7",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "\n",
        "## 1. Generate Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvaa_YKfSOVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(generator, save_dir):\n",
        "    noise = gen_noise(batch_size,noise_shape)\n",
        "    fake_data_X = generator.predict(noise)\n",
        "    print(\"Displaying generated images\")\n",
        "    plt.figure(figsize=(16,16))\n",
        "    gs1 = gridspec.GridSpec(4, 4)\n",
        "    gs1.update(wspace=0, hspace=0)\n",
        "    rand_indices = np.random.choice(fake_data_X.shape[0],16,replace=False)\n",
        "    for i in range(16):\n",
        "        ax1 = plt.subplot(gs1[i])\n",
        "        ax1.set_aspect('equal')\n",
        "        rand_index = rand_indices[i]\n",
        "        image = fake_data_X[rand_index, :,:,:]\n",
        "        fig = plt.imshow(denorm_img(image))\n",
        "        plt.axis('off')\n",
        "        fig.axes.get_xaxis().set_visible(False)\n",
        "        fig.axes.get_yaxis().set_visible(False)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_dir+str(time.time())+\"_GENERATEDimage.png\",bbox_inches='tight',pad_inches=0)\n",
        "    plt.show()\n",
        "\n",
        "generate_images(generator, img_save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oehouUu2lQjM",
        "colab_type": "text"
      },
      "source": [
        "## 2. Loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6vKOkBylHPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_real_loss = np.array(avg_disc_real_loss)\n",
        "disc_fake_loss = np.array(avg_disc_fake_loss)\n",
        "GAN_loss = np.array(avg_GAN_loss)\n",
        "\n",
        "# Plot the losses vs training steps\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(range(0,num_steps), disc_real_loss, label=\"Discriminator Loss - Real\")\n",
        "plt.plot(range(0,num_steps), disc_fake_loss, label=\"Discriminator Loss - Fake\")\n",
        "plt.plot(range(0,num_steps), GAN_loss, label=\"Generator Loss\")\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('GAN Loss')\n",
        "plt.grid(True)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4DrcLgoCGU",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create GIF for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvxtZ8-ToAJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating GIF from PNGs\n",
        "import imageio\n",
        "# create a list of PNGs\n",
        "generated_images = [img_save_dir+str(x).zfill(4)+\"_image.png\" for x in range(0,num_steps,100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BdpY5u-plce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "for filename in generated_images:\n",
        "    images.append(imageio.imread(filename))\n",
        "\n",
        "imageio.mimsave(img_save_dir+'movie.gif', images) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqPNyVnSqru1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "with open(\"images/movie.gif\",'rb') as f:\n",
        "    display(Image(data=f.read(), format='png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0dzY_sRlbx5",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In this Project, we learned about the structure of GANs, Discriminators, Generators and how to train a GAN to generate images. This model is not very good at generating fake images, yet we get to understand the basics of GANs with this project and we are fired up to build more interesting and complex projects as we go forward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNOvBnQCl-CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}