{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2019komazawa_exam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "920iZIVtVzdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title # 2019年度駒澤大学文学部心理学特講IIIA {display-mode: \"form\"}\n",
        "\n",
        "name = '氏名'  #@param {type: \"string\"}\n",
        "name_kana = 'ふりがな'  #@param {type: \"string\"}\n",
        "id = '学生番号'  #@param {type: \"string\"}\n",
        "date = '2019-07-16'  #@param {type: \"date\"}\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HcoCZo13ahdC",
        "colab": {}
      },
      "source": [
        "#@title ## 問題 {display-mode: \"form\"}\n",
        "#@markdown ### 問1. 深層学習(ディープラーニング)で用いられる以下の略語の本来の綴りを記し，一行程度でその意味を簡潔に説明せよ\n",
        "term1 = 'CNN: '  #@param {type: \"string\"}\n",
        "description1 = '説明:'  #@param {type: \"string\"}\n",
        "\n",
        "term2 = 'RNN: '  #@param {type: \"string\"}\n",
        "description2 = '説明:'  #@param {type: \"string\"}\n",
        "\n",
        "term3 = 'RL: '  #@param {type: \"string\"}\n",
        "description3 = '説明: '  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### 問 2-1. 授業で取り上げた話題の中で <font color='red'>もっとも印象に残っている</font> 話題を一つ挙げよ。また簡単に，1行程度でその理由を記せ\n",
        "topic2_1 = '話題1: '  #@param {type: \"string\"}\n",
        "reason2_1 = '理由1:'  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### 問 2-2. 授業で取り上げた話題の中で <font color='red'>2番目に印象に残っている</font> 話題を一つ挙げよ。また簡単に，1行程度でその理由を記せ\n",
        "topic2_2 = '話題2:'  #@param {type: \"string\"}\n",
        "reason2_2 = '理由2:'  #@param {type: \"string\"}\n",
        "\n",
        "#@markdown ### 問 2-3. 授業で取り上げた話題の中で <font color='red'>もっとも興味が持てなかった</font> 話題を一つ挙げよ。また簡単に，1行程度でその理由を記せ\n",
        "topic2_3 = '話題3:'  #@param {type: \"string\"}\n",
        "reason2_3 = '理由3:'  #@param {type: \"string\"}\n",
        "#@markdown ---\n",
        "x1 = \"\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y_eSq032cA4",
        "colab_type": "text"
      },
      "source": [
        "## 空間的注意とディープニューラルネットワークの解釈性\n",
        "\n",
        "- [オリジナルコード](https://research.google.com/seedbank/seed/spatialchannel_attribution)\n",
        "- [元論文](https://distill.pub/2018/building-blocks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_x2U5na3JmX",
        "colab_type": "text"
      },
      "source": [
        "### 準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsIVpeX3Msf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --quiet lucid==0.0.5\n",
        "!npm install -g svelte-cli@2.2.0\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import lucid.modelzoo.vision_models as models\n",
        "from lucid.misc.io import show\n",
        "import lucid.optvis.render as render\n",
        "from lucid.misc.io import show, load\n",
        "from lucid.misc.io.reading import read\n",
        "from lucid.misc.io.showing import _image_url\n",
        "from lucid.misc.gradient_override import gradient_override_map\n",
        "import lucid.scratch.web.svelte as lucid_svelte"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mYR3xu-3TJN",
        "colab_type": "text"
      },
      "source": [
        "### モデルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5LQowF63P6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.InceptionV1()\n",
        "model.load_graphdef()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu8mn2t93Zh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ラベルの読み込み\n",
        "labels_str = read(\"https://gist.githubusercontent.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57/raw/aa66dd9dbf6b56649fa3fab83659b2acbf3cbfd1/map_clsloc.txt\")\n",
        "labels = [line[line.find(\" \"):].strip() for line in labels_str.split(\"\\n\")]\n",
        "labels = [label[label.find(\" \"):].strip().replace(\"_\", \" \") for label in labels]\n",
        "labels = [\"dummy\"] + labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEyCDHV_3fYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw_class_spatial_attr(img, layer, label, override=None):\n",
        "  \"\"\"How much did spatial positions at a given layer effect a output class?\"\"\"\n",
        "\n",
        "  # Set up a graph for doing attribution...\n",
        "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
        "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
        "    T = render.import_model(model, t_input, t_input)\n",
        "    \n",
        "    # Compute activations\n",
        "    acts = T(layer).eval()\n",
        "    \n",
        "    if label is None: return np.zeros(acts.shape[1:-1])\n",
        "    \n",
        "    # Compute gradient\n",
        "    score = T(\"softmax2_pre_activation\")[0, labels.index(label)]\n",
        "    t_grad = tf.gradients([score], [T(layer)])[0]   \n",
        "    grad = t_grad.eval({T(layer) : acts})\n",
        "    \n",
        "    # Linear approximation of effect of spatial position\n",
        "    return np.sum(acts * grad, -1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81G595zO3gQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def raw_spatial_spatial_attr(img, layer1, layer2, override=None):\n",
        "  \"\"\"Attribution between spatial positions in two different layers.\"\"\"\n",
        "\n",
        "  # Set up a graph for doing attribution...\n",
        "  with tf.Graph().as_default(), tf.Session(), gradient_override_map(override or {}):\n",
        "    t_input = tf.placeholder_with_default(img, [None, None, 3])\n",
        "    T = render.import_model(model, t_input, t_input)\n",
        "    \n",
        "    # Compute activations\n",
        "    acts1 = T(layer1).eval()\n",
        "    acts2 = T(layer2).eval({T(layer1) : acts1})\n",
        "    \n",
        "    # Construct gradient tensor\n",
        "    # Backprop from spatial position (n_x, n_y) in layer2 to layer1.\n",
        "    n_x, n_y = tf.placeholder(\"int32\", []), tf.placeholder(\"int32\", [])\n",
        "    layer2_mags = tf.sqrt(tf.reduce_sum(T(layer2)**2, -1))[0]\n",
        "    score = layer2_mags[n_x, n_y]\n",
        "    t_grad = tf.gradients([score], [T(layer1)])[0]\n",
        "    \n",
        "    # Compute attribution backwards from each positin in layer2\n",
        "    attrs = []\n",
        "    for i in range(acts2.shape[1]):\n",
        "      attrs_ = []\n",
        "      for j in range(acts2.shape[2]):\n",
        "        grad = t_grad.eval({n_x : i, n_y : j, T(layer1) : acts1})\n",
        "        # linear approximation of imapct\n",
        "        attr = np.sum(acts1 * grad, -1)[0]\n",
        "        attrs_.append(attr)\n",
        "      attrs.append(attrs_)\n",
        "  return np.asarray(attrs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc9wAhKD3jKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def orange_blue(a,b,clip=False):\n",
        "  if clip:\n",
        "    a,b = np.maximum(a,0), np.maximum(b,0)\n",
        "  arr = np.stack([a, (a + b)/2., b], -1)\n",
        "  arr /= 1e-2 + np.abs(arr).max()/1.5\n",
        "  arr += 0.3\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljQTMMF33pQ0",
        "colab_type": "text"
      },
      "source": [
        "### 空間属性のためのインターフェイス\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OCNI2603l9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%html_define_svelte SpatialWidget\n",
        "\n",
        "<div class=\"figure\" style=\"width: 500px; height: 250px; contain: strict;\">\n",
        "  <div class=\"outer\" on:mouseleave=\"set({pos2: undefined})\">\n",
        "    <img class=\"img\"  src=\"{{img}}\">\n",
        "    <img class=\"attr\" src=\"{{(pos1 == undefined)? hint1 : spritemap1[pos1[1]][pos1[0]]}}\">\n",
        "\n",
        "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size1}} {{size1}}\">\n",
        "      {{#each xs1 as x}}\n",
        "      {{#each ys1 as y}}\n",
        "        <rect x={{x}} y={{y}} width=1 height=1\n",
        "          class={{(pos2 != undefined && x == pos2[0] && y == pos2[1])? \"selected\" : \"\"}}\n",
        "          on:mouseover=\"set({pos2: [x,y], pos1: undefined})\"></rect>\n",
        "      {{/each}}\n",
        "      {{/each}}\n",
        "    </svg> \n",
        "\n",
        "    <div class=\"label\">{{layer1}}</div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"outer\" on:mouseleave=\"set({pos1: undefined})\">\n",
        "    <img class=\"img\" src=\"{{img}}\">\n",
        "    <img class=\"attr\" src=\"{{(pos2 == undefined)? hint2 : spritemap2[pos2[1]][pos2[0]]}}\">\n",
        "\n",
        "    <svg class=\"pointer_container\" viewBox=\"0 0 {{size2}} {{size2}}\">\n",
        "      {{#each xs2 as x}}\n",
        "      {{#each ys2 as y}}\n",
        "        <rect x={{x}} y={{y}} width=1 height=1\n",
        "          class={{(pos1 != undefined && x == pos1[0] && y == pos1[1])? \"selected\" : \"\"}}\n",
        "          on:mouseover=\"set({pos1: [x,y], pos2: undefined})\"></rect>\n",
        "      {{/each}}\n",
        "      {{/each}}\n",
        "    </svg> \n",
        "\n",
        "    <div class=\"label\">{{layer2}}</div>\n",
        "  </div>\n",
        "  \n",
        "</div>\n",
        "\n",
        "\n",
        "<style>\n",
        "\n",
        "  .outer{\n",
        "    width: 224px;\n",
        "    height: 224px;\n",
        "    display: inline-block;\n",
        "    margin-right: 2px;\n",
        "    position: relative;\n",
        "  }\n",
        "  .outer img, .outer svg {\n",
        "    position: absolute;\n",
        "    left: 0px;\n",
        "    top: 0px;\n",
        "    width: 224px;\n",
        "    height: 224px;\n",
        "    image-rendering: pixelated; \n",
        "  }\n",
        "  .attr {\n",
        "    opacity: 0.6;\n",
        "  }\n",
        "  .pointer_container {\n",
        "    z-index: 100;\n",
        "  }\n",
        "  .pointer_container rect {\n",
        "    opacity: 0;\n",
        "  }\n",
        "  .pointer_container .selected  {\n",
        "    opacity: 1;\n",
        "    fill: none;\n",
        "    stroke: hsl(24, 100%, 50%);\n",
        "    stroke-width: 0.1px;\n",
        "  }\n",
        "  .label{\n",
        "    position: absolute;\n",
        "    left: 0px;\n",
        "    top: 226px;\n",
        "    width: 224px;\n",
        "  }\n",
        "</style>\n",
        "\n",
        "<script>\n",
        "  function range(n){\n",
        "    return Array(n).fill().map((_, i) => i);\n",
        "  }\n",
        "  \n",
        "  export default {\n",
        "    data () {\n",
        "      return {\n",
        "        img: \"\",\n",
        "        hint1: \"\",\n",
        "        hint2: \"\",\n",
        "        spritemap1 : \"\",\n",
        "        size1: 1,\n",
        "        spritemap2 : \"\",\n",
        "        size2: 1,\n",
        "        pos1: undefined,\n",
        "        pos2: undefined,\n",
        "        layer1: \"\",\n",
        "        layer2: \"\"\n",
        "      };\n",
        "    },\n",
        "    computed: {\n",
        "      xs1: (size1) => range(size1),\n",
        "      ys1: (size1) => range(size1),\n",
        "      xs2: (size2) => range(size2),\n",
        "      ys2: (size2) => range(size2)\n",
        "    },\n",
        "    helpers: {range}\n",
        "  };\n",
        "</script>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umKHJa8_35uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_url_grid(grid):\n",
        "  return [[_image_url(img) for img in line] for line in grid ]\n",
        "\n",
        "def spatial_spatial_attr(img, layer1, layer2, hint_label_1=None, hint_label_2=None, override=None):\n",
        "  \n",
        "  hint1 = orange_blue(\n",
        "      raw_class_spatial_attr(img, layer1, hint_label_1, override=override),\n",
        "      raw_class_spatial_attr(img, layer1, hint_label_2, override=override),\n",
        "      clip=True\n",
        "  )\n",
        "  hint2 = orange_blue(\n",
        "      raw_class_spatial_attr(img, layer2, hint_label_1, override=override),\n",
        "      raw_class_spatial_attr(img, layer2, hint_label_2, override=override),\n",
        "      clip=True\n",
        "  )\n",
        "\n",
        "  attrs = raw_spatial_spatial_attr(img, layer1, layer2, override=override)\n",
        "  attrs = attrs / attrs.max()\n",
        "  \n",
        "  lucid_svelte.SpatialWidget({\n",
        "    \"spritemap1\": image_url_grid(attrs),\n",
        "    \"spritemap2\": image_url_grid(attrs.transpose(2,3,0,1)),\n",
        "    \"size1\": attrs.shape[3],\n",
        "    \"layer1\": layer1,\n",
        "    \"size2\": attrs.shape[0],\n",
        "    \"layer2\": layer2,\n",
        "    \"img\" : _image_url(img),\n",
        "    \"hint1\": _image_url(hint1),\n",
        "    \"hint2\": _image_url(hint2)\n",
        "  })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8mLm86P3-AS",
        "colab_type": "text"
      },
      "source": [
        "### 簡単な例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZXyWNe84CiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/dog_cat.png\")\n",
        "spatial_spatial_attr(img, \"mixed4a\", \"mixed4d\", hint_label_1=\"Labrador retriever\", hint_label_2=\"tiger cat\")\n",
        "print \"\\n両画像の対応関係を調べるためにマウスを画像上で動かしてみてください\\n\"\n",
        "print \"フニャフニャな耳ととがった耳の違いがラブラドール・レトリーバーとトラネコとの違いであることが分かります\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P__vivDI4gG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/flowers.png\")\n",
        "spatial_spatial_attr(img, \"mixed4a\", \"mixed4d\", hint_label_1=\"lemon\", hint_label_2=\"vase\")\n",
        "print \"\\n両画像の対応関係を調べるためにマウスを画像上で動かしてみてください\\n\"\n",
        "print \"では花瓶とレモンとを分ける特徴は何でしょうか？\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhNhS95J6Sie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = load(\"https://storage.googleapis.com/lucid-static/building-blocks/examples/beer.jpeg\")\n",
        "spatial_spatial_attr(img, \"mixed4a\", \"mixed4d\", hint_label_1=\"beer glass\", hint_label_2=\"wine bottle\")\n",
        "print \"\\n両画像の対応関係を調べるためにマウスを画像上で動かしてみてください\\n\"\n",
        "print \"ワインボトルとビール用のグラフを見分けるためにニューロンは何を見ているのでしょうか？\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkewpOwf5GMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://distill.pub/2018/building-blocks/examples/input_images/dog_cat.jpeg\n",
        "#https://distill.pub/2018/building-blocks/examples/input_images/chain.jpeg\n",
        "#https://distill.pub/2018/building-blocks/examples/input_images/beer.jpeg"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}